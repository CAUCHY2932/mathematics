## Hadoop大数据平台架构与实践课程简介
https://www.imooc.com/video/7642

大数据技术的相关概念
Hadoop的架构和运行机制

实战Hadoop的安装和配置
Hadoop开发


## 预备基础知识
    Linux基础知识
    Java编程基础

## 推荐书籍
    Hadoop权威指南
    Hadoop技术详解

## 解决大数据技术的难点
    google大数据技术
    MapReduce、BigTable、GFS

## Hadoop生态

### hive 
sql语句转化为Hadoop任务
### hbase 
和传统关系型数据库的区别是hbase放弃了事务特性，追求更高的扩展。

和hdfs的区别是提供数据的随机读写和实时访问，实现对表数据的读写功能
### zookeeper
维护结点
## 版本选择
1.2更稳定
2.x版本变动较大
暂时选择1.2版本进行学习

## 安装Hadoop
### 获取一个Linux系统
租用云主机
阿里云
腾讯云
unitedstack

### 安装jdk
### 安装Hadoop



## 开发语言与生态

| 技术框架 | 开发语言 |
| -------- | :------- |
| hadoop   | java     |
| hive     | java     |
| storm    | clojure  |
| kafka    | scala    |
| spark    | scala    |
| flink    | scala    |


## 学习地址

>https://www.imooc.com/video/16284
## Hadoop平台
### 课程简介
#### 理论知识
    大数据的相关概念及行业生态
    Hadoop的基础原理及其架构
#### 应用知识
    实战：hdfs实际操作







## 企业级大数据框架

#### 数据收集
## 企业级大数据技术体系的概述

数据收集层

数据存储层

资源管理与服务协调层

计算引擎层

数据分析层

数据可视化层


## 关系数据的收集

sqoop
可以记忆为sql+hadoop
解决关系型数据库与Hadoop之间的数据传输问题

    数据迁移
    可视化分析结果
    数据增量导入

sqoop2使用方式

1)connector

    generic-jdbc-connector
    hdfs-connector
    kafka-connector
    kite-connector
2)link
3)job

cdc增量数据收集


canal阿里巴巴旗下利用Java开发的一款数据库增量日志解析系统

otter阿里巴巴给予canal开发的一款解决多机房同步数据问题的系统

---
### 非关系型数据的收集

1）flume设计动机
日志

数据源种类繁多

数据源是物理分布的

流式的，不间断产生的

对可靠性有一定要求

2）flume基本思想及特点

良好的扩展性

高度定制化

声明式动态化配置

语意路由

flume NG

基本架构
flume传递的数据称之为event

source
channel

flume NG高级组件

interceptor

sink processor

flume NG数据流拓扑构建方法
1）如何构建数据流拓扑
流式数据获取方式
远程过程调用
tcp或是udp
执行命令

常见的拓扑结构

多路合并和多路复用

agent配置方式

数据流拓扑实例剖析

### 分布式消息队列kafka

kafka设计动机

每一条业务都是一条数据流水线

数据生产者和消费者耦合度过高，当需要增加一种新的消费者时，所有数据生产者均需要被改动
使得整个数据流水线扩展性非常差

生产者和消费者数据处理速率不对等


大量并发的网络连接对后端消费者不够友好


消息中间件

消息队列


kafka特点

高性能

良好对扩展性

数据持久性

kafka设计架构

producer

broker

consumer


kafka关键技术点

    可控的可靠性级别
    数据多副本
    高效的持久化机制
    数据传输优化，批处理与zero-copy技术
    可控的消息传递语义

kafka程序设计

producer程序设计

kafka典型应用场景

    消息队列
    流式计算框架的数据源
    分布式日志收集系统中的source或sink
    lambda architecture中的source

### 数据存储

#### 数据序列化与文件存储格式

    数据序列化
    文件存储格式
    存储系统

#### 数据序列化的意义

阶段1:不考虑任何复杂的序列化方案，直接将数据转化成字符串，以文本形式保存或传输


但是难以嵌套数据，无法表达二进制数据，难以应对数据模式变化


阶段2:采用编程语言的序列化机制，比如Java serialization，python pickle

很难做到跨语言数据的写入和输出

阶段3:json和xml

严重的性能问题，解析速度慢，数据存储冗余较大，比如json会重复存储每个属性的名称

阶段4:期望出现一种带有schema描述的数据表示格式，通过统一化的schema描述，可约束每个字段的类型，进而为存储和解析数据带来优化的可能，此外，统一schema的引入，可减少属性名称重复存储带来的开销，同时，也有利于数据共享


序列化框架
thrift，protocol，buffers和avro

idl接口描述语言
#### 数据序列化方案

序列化框架thrift

序列化框架protobuf

序列化框架avro


序列化框架对比

性能方面


非功能方面

文件存储格式解析


行存储与列存储


行存储



列存储

orc文件

支持复杂数据类型



